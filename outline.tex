% Introduction
  % Variationist work has traditionally focused on a handful of bellweather variables and generalized out from there.
    % This is the case despite the more holistic approaches from work in dialectology that came before.
    % Variationist work in CMC has allowed for many more variables to be included at a time, moving back towards a holistic approach.
    % The objective for this study is to develop a method for comparing the languages of communities holistically, including practically all possible variables.
  % Variationist work that makes generalizes to communities from small sets of variables
    % Which group distinctions have been drawn
    % What are the advantages of this approach
    % What assumptions remain that call for more holistic analyses
  % Variationist work in CMC that brings in many more variables
    % CMC definition and characteristics
    % Which group distinctions have been drawn
    % What sort of variables are used
    % This is holistic, but is it holistic enough?
  % An even more holistic approach is to use character n-gram and word n-gram language models
    % This has been used in classifiers in NLP for the task of language variety identification
    % The success of these models in distinguishing between even minorly different language varieties suggests that they can be compared to quantify the linguistic distance between two varieties, as well
      % Language models in NLP are, after all, essentially just probability distributions over some set of symbols
  % Research question
    % Are n-gram language models useful for quantifying the linguistic distance between communities?
% Methods
  % Data collection
    % The europarl corpus
      % This is a parallel corpus that can be used to set the baseline for what one should expect between what are generally viewed as completely different languages and between one variety at different times
        % For different languages: built models from the English and French documents
        % For one variety: built models from the first and second halves of the English documents
        % In effect, this data can be said to be coded for language and text section
    % Twitter data
      % Characteristics of Twitter
        % What makes this appropriate for this study
      % Tweets collected from Louisiana and filtered for discussion of race and ethnicity
        % Narrowing the type of data analyzed helps ensure that distinctions between communities won't be the result of simply different topics of conversation
        % The race/ethnicity situation in Louisiana has been analyzed before and is complex, so narrowing in this way may provide insights into social questions, though that's not the primary objective of this study
      % Coding
        % The goal here is to compare linguistic distance between communities but also to consider what factors may draw those communities together
        % Community detection
          % Communities are conceptualized on structural grounds in that those who interact with the same people on a consistent basis are considered to form a community
            % In this case, a directed tweet counts as the sender interacting with the receiver
            % The number of directed tweets between two users counts as the amount of interaction
          % Newman & Girvan's (2004) community detection algorithm is used
  % Language models
    % Following Duvenhage (2019) due to his success for DSL 17, both word and character n-grams were trained, unigrams and bigrams for the former, bigrams, 4-grams, and 6-grams for the latter.
      % These models each capture different levels of the language, so I conceptualize them as follows:
        % Word unigrams: lexicon
        % Word bigrams: syntax (or at least some small amount of syntax)
        % Character n-grams: orthography and morphology
  % Analysis
    % Two statistics are used: KL divergence and cosine similarity
      % Both of these show essentially the same thing (i.e., how similar/different two distributions are), but the former is easier to interpret and the latter makes comparisons between language pairs more doable
      % These are calculated for like-models (e.g., word unigram to word unigram, character 4-gram to character 4-gram, etc.)
        % This makes it possible to see how distance two varieties are on different linguistic levels
% Results
% Discussion
